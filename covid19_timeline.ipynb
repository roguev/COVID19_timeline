{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "import geopandas as gpd\n",
    "import geoplot as gplot\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some helper functions first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(line, start_year='2020'):\n",
    "    ''' extract date from dataset'''\n",
    "    \n",
    "    MONTHS = {'January' : '01',\n",
    "              'February' :'02' ,\n",
    "              'March' : '03', \n",
    "              'April' : '04',\n",
    "              'May' : '05',\n",
    "              'June' : '06',\n",
    "              'July' : '07',\n",
    "              'August' : '08',\n",
    "              'September' : '09',\n",
    "              'October' : '10',\n",
    "              'November' : '11',\n",
    "              'December' : '12'}\n",
    "    \n",
    "    date = False\n",
    "    \n",
    "    for m in MONTHS:\n",
    "        pattern = '^\\d+\\s+' + m\n",
    "        if re.match(pattern,line):\n",
    "            tokens = re.split('\\s+',line)\n",
    "            if len(tokens[0]) < 2:\n",
    "                tokens[0] = '0' + tokens[0]    \n",
    "            date = start_year + MONTHS[m] + tokens[0]\n",
    "            \n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load geography data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freo https://datahub.io/core/world-cities#resource-world-cities\n",
    "world_data = pd.read_csv('world-cities.csv')\n",
    "world_data = world_data.astype({'country' : str, 'subcountry' : str, 'name' : str})\n",
    "world_data.loc[world_data['country'] == 'nan','country'] = 'unknown'\n",
    "world_data.loc[world_data['subcountry'] == 'nan','subcountry'] = 'unknown'\n",
    "world_data.loc[world_data['name'] == 'nan','name'] = 'unknown'\n",
    "\n",
    "world_data['subcountry'] = world_data['subcountry'].apply(lambda x : x.replace(' Sheng',''))\n",
    "world_data['subcountry'] = world_data['subcountry'].apply(lambda x : x.replace(' Shi',''))\n",
    "world_data['subcountry'] = world_data['subcountry'].apply(lambda x : x.replace(' Zhuangzu',''))\n",
    "world_data['subcountry'] = world_data['subcountry'].apply(lambda x : x.replace(' Uygur',''))\n",
    "world_data['subcountry'] = world_data['subcountry'].apply(lambda x : x.replace(' Zizhiqu',''))\n",
    "world_data['subcountry'] = world_data['subcountry'].apply(lambda x : x.replace(' Autonomous Region',''))\n",
    "world_data['subcountry'] = world_data['subcountry'].apply(lambda x : x.replace(' Huizu',''))\n",
    "\n",
    "countries_l = world_data['country'].unique()\n",
    "regions_l = world_data['subcountry'].unique()\n",
    "cities_l = world_data['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# China\n",
    "# from https://github.com/deldersveld/topojson\n",
    "china = gpd.read_file('china-provinces.json')\n",
    "china.loc[china['NAME_1'] == 'Nei Mongol','NAME_1'] = 'Inner Mongolia'\n",
    "china.loc[china['NAME_1'] == 'Xinjiang Uygur','NAME_1'] = 'Xinjiang'\n",
    "china.loc[china['NAME_1'] == 'Xizang','NAME_1'] = 'Tibet'\n",
    "china.loc[china['NAME_1'] == 'Ningxia Hui','NAME_1'] = 'Ningxia'\n",
    "china.rename(columns={'NAME_1' : 'geounit'}, inplace=True)\n",
    "\n",
    "# world\n",
    "world = gpd.read_file('world-countries.json')\n",
    "world = world.drop(world.loc[world['geometry'].is_empty].index)\n",
    "world.rename(columns = {'name' : 'geounit'}, inplace=True)\n",
    "world.loc[world['geounit'] == 'United States of America','geounit'] = 'United States'\n",
    "# make the UK\n",
    "world.loc[world['geounit'] == 'England','geounit'] = 'United Kingdom'\n",
    "world.loc[world['geounit'] == 'Scotland','geounit'] = 'United Kingdom'\n",
    "world.loc[world['geounit'] == 'Wales','geounit'] = 'United Kingdom'\n",
    "world.loc[world['geounit'] == 'Northern Ireland','geounit'] = 'United Kingdom'\n",
    "\n",
    "# USA\n",
    "usa = gpd.read_file('us-albers.json')\n",
    "usa = usa.drop(usa.loc[usa['geometry'].is_empty].index)\n",
    "usa.rename(columns={'name' : 'geounit'},inplace=True)\n",
    "\n",
    "# europe\n",
    "europe = gpd.read_file('europe.json')\n",
    "europe.drop(europe.loc[europe['geometry'].is_empty].index,inplace=True)\n",
    "# remove Russie for now\n",
    "europe.drop(europe.loc[europe['geounit']=='Russia'].index,inplace=True)\n",
    "# make the UK\n",
    "europe.loc[europe['geounit'] == 'England','geounit'] = 'United Kingdom'\n",
    "europe.loc[europe['geounit'] == 'Scotland','geounit'] = 'United Kingdom'\n",
    "europe.loc[europe['geounit'] == 'Wales','geounit'] = 'United Kingdom'\n",
    "europe.loc[europe['geounit'] == 'Northern Ireland','geounit'] = 'United Kingdom'\n",
    "\n",
    "# africa\n",
    "africa = gpd.read_file('africa.json')\n",
    "africa.drop(africa.loc[africa['geometry'].is_empty].index,inplace=True)\n",
    "\n",
    "# asia\n",
    "asia = gpd.read_file('asia.json')\n",
    "asia.drop(asia.loc[asia['geometry'].is_empty].index,inplace=True)\n",
    "# remove Russie for now\n",
    "asia.drop(asia.loc[asia['geounit']=='Russia'].index,inplace=True)\n",
    "\n",
    "# south america\n",
    "samerica = gpd.read_file('south-america.json')\n",
    "samerica.drop(samerica.loc[samerica['geometry'].is_empty].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest COVID19 data and turn it into list of lines\n",
    "source: https://bnonews.com/index.php/2020/02/the-latest-coronavirus-cases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest data\n",
    "with open('covid19.txt','r') as f:\n",
    "    # read everything in a single string\n",
    "    text = f.read()\n",
    "\n",
    "# get rid on new lines and build a list\n",
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse data and attempt to extract meaningful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a dict to hold data, will turn it into dataframe later\n",
    "parsed = {}\n",
    "parsed['date'] = []\n",
    "parsed['time'] = []\n",
    "parsed['timestamp'] = []\n",
    "parsed['country'] = []\n",
    "parsed['region'] = []\n",
    "parsed['new_cases'] = []\n",
    "parsed['new_deaths'] = []\n",
    "\n",
    "# parse data\n",
    "# i feel the code below can be greatly improved, it is by no means a very good solution\n",
    "current_date = None\n",
    "for line in lines:   \n",
    "    date = extract_date(line)\n",
    "    if date:\n",
    "        current_date = date\n",
    "        continue\n",
    "\n",
    "    #print(line)\n",
    "    \n",
    "    country = 'unknown'\n",
    "    subregion = 'unknown'\n",
    "    city = 'unknown'\n",
    "    new_cases = 0\n",
    "    new_deaths = 0\n",
    "    timestamp = 'unknown'\n",
    "    \n",
    "    # timestamp\n",
    "    pattern = '^\\d+:\\d+'\n",
    "    z = re.findall(pattern,line)\n",
    "    if z:\n",
    "        timestamp = z[0].split(' ')[0]\n",
    "    else:\n",
    "        timestamp = '00:00'\n",
    "    \n",
    "    line = line.replace(timestamp+': ','')\n",
    "    line = line.replace(\"'s\",'')\n",
    "    timestamp = timestamp.replace(':','')\n",
    "    \n",
    "    # doctor the line\n",
    "    line = line.replace(',',' , ')\n",
    "    line = line.replace('.',' . ')\n",
    "    \n",
    "    lc = line.split('. ')[0]\n",
    "    #print(lc)\n",
    "\n",
    "    # get country\n",
    "    for x in countries_l:\n",
    "        if lc.find(x + ' ') > -1:\n",
    "            country = x\n",
    "            break\n",
    "    \n",
    "    # get subregion (state/ provonce etc)\n",
    "    for x in regions_l:\n",
    "        if lc.find(x + ' ') > -1:\n",
    "            subregion = x\n",
    "            break\n",
    "    \n",
    "    # get city\n",
    "    for x in cities_l:\n",
    "        if lc.find(x + ' ') > -1:\n",
    "            city = x\n",
    "            break\n",
    "                \n",
    "    # new cases\n",
    "    pattern = '\\d+\\s+new\\s+case|\\d+\\s+case'\n",
    "    z = re.findall(pattern,lc)\n",
    "    if z:\n",
    "        new_cases = z[0].split(' ')[0]\n",
    "    \n",
    "    # capture numbers like 1,123\n",
    "    pattern = '\\d+\\s,\\s\\d+\\s+new\\s+case|\\d+\\s,\\s\\d+\\s+case'\n",
    "    z = re.findall(pattern,lc)\n",
    "    if z:\n",
    "        new_cases = z[0].replace(' , ','').split(' ')[0]\n",
    "        \n",
    "    pattern = 'First\\s\\d+\\scase'\n",
    "    z = re.findall(pattern,lc)\n",
    "    if z:\n",
    "        new_cases = z[0].split(' ')[1]\n",
    "        \n",
    "    pattern = 'First\\s+case'\n",
    "    z = re.findall(pattern,lc)\n",
    "    if z:\n",
    "        new_cases = 1\n",
    "    \n",
    "    # deaths\n",
    "    pattern = '\\d+\\s+new\\s+death|\\d+\\s+death'\n",
    "    z = re.findall(pattern,lc)\n",
    "    if z:\n",
    "        new_deaths = z[0].split(' ')[0]\n",
    "    \n",
    "    # capture numbers like 1,123\n",
    "    pattern = '\\d+\\s,\\s\\d+\\s+new\\s+death|\\d+\\s,\\s\\d+\\s+death'\n",
    "    z = re.findall(pattern,lc)\n",
    "    if z:\n",
    "        new_deaths = z[0].replace(' ','').split(' ')[0]    \n",
    "    \n",
    "    # try to guess country based on subregion\n",
    "    if country == 'unknown':\n",
    "        if subregion != 'unknown':\n",
    "            country = world_data.loc[world_data['subcountry'] == subregion, 'country'].values[0]\n",
    "    \n",
    "    # try to guess country based on city\n",
    "    if country == 'unknown':\n",
    "        if city != 'unknown':\n",
    "            country = world_data.loc[world_data['name'] == city, 'country'].values[0]\n",
    "    \n",
    "    # try to guess subregion based on city\n",
    "    if subregion == 'unknown':\n",
    "        if city != 'unknown':\n",
    "            subregion = world_data.loc[world_data['name'] == city, 'subcountry'].values[0]\n",
    "    \n",
    "    #print('%s\\t%s\\t%s\\t%s\\t%s' %(country,subregion,city,new_cases,new_deaths))\n",
    "    \n",
    "    if new_cases == 0 and new_deaths == 0:\n",
    "        continue\n",
    "    \n",
    "    # give up if country still unknown\n",
    "    if country == 'unknown':\n",
    "        # inform on failures\n",
    "        print('@ ' + line)\n",
    "        continue\n",
    "                \n",
    "    parsed['date'].append(current_date)\n",
    "    parsed['country'].append(country)\n",
    "    parsed['region'].append(subregion)\n",
    "    parsed['timestamp'].append(timestamp)\n",
    "    parsed['time'].append(str(current_date)+str(timestamp))\n",
    "    parsed['new_cases'].append(new_cases)\n",
    "    parsed['new_deaths'].append(new_deaths)\n",
    "    \n",
    "    #print('%s\\t%s\\t%s\\t%s\\t%s\\t%s' %(current_date,timestamp,country,subregion, new_cases, new_deaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create dataframe for further use\n",
    "df = pd.DataFrame(parsed)\n",
    "\n",
    "# convert columns to numeric\n",
    "df = df.astype({'new_cases' : int,\n",
    "                'new_deaths' : int,\n",
    "                'date' : int,\n",
    "                'time' : int,\n",
    "                'timestamp' : int\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following 2 functions do the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_sub_frame(params=None): \n",
    "    # normalize colormap\n",
    "    norm = mpl.colors.Normalize(vmin=params['color_min'], vmax=params['color_max'])\n",
    "    cmap = mpl.cm.ScalarMappable(norm=norm, cmap=params['cmap']).cmap\n",
    "    \n",
    "    feature = params['feature']\n",
    "    raw_feature = feature + '_raw'\n",
    "    time_point = params['time_point']\n",
    "    \n",
    "    # sum numbers by country, take log10\n",
    "    s = params['data'].loc[ params['data']['time'] <= time_point ].groupby('country')[feature].sum()\n",
    "    \n",
    "    # merge w/ map data\n",
    "    geodata = params['map_data'].copy()\n",
    "    geodata[feature] = np.zeros(geodata.shape[0])\n",
    "    geodata[raw_feature] = np.zeros(geodata.shape[0])\n",
    "    \n",
    "    for country in s.index:\n",
    "        geodata.loc[geodata['geounit'] == country,feature] = np.log10(s.loc[country])\n",
    "        geodata.loc[geodata['geounit'] == country,raw_feature] = s.loc[country]\n",
    "    \n",
    "    #legend_values = [10**x for x in range(params['color_min'],params['color_max']+1)]\n",
    "    #legend_labels = legend_values\n",
    "    \n",
    "    #print(geodata.head(n=50))\n",
    "    \n",
    "    gplot.choropleth(geodata,\n",
    "                     hue=feature,\n",
    "                     cmap=cmap,\n",
    "                     ax=params['ax'],\n",
    "                     norm=norm,\n",
    "                     legend = True,\n",
    "     #                legend_values = legend_values,\n",
    "     #                legend_labels = legend_labels\n",
    "                    )\n",
    "    \n",
    "    if params['annot']:\n",
    "        for ix,row in geodata.iterrows():\n",
    "            centroid = row['geometry'].centroid.coords\n",
    "            x0 = centroid[0][0]\n",
    "            y0 = centroid[0][1]\n",
    "            params['ax'].text(x0, y0, int(row[raw_feature]), fontsize=10)\n",
    "    \n",
    "    # derive date and time for plot title\n",
    "    str_date = str(time_point)[0:4] + '-' +str(time_point)[4:6]+ '-' +str(time_point)[6:8]\n",
    "    str_time = str(time_point)[8:] \n",
    "    params['ax'].set_title('COVID19 '+ params['title_annot'] +' over time ' + str_date + ' ' + str_time)\n",
    "    del geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_region(data=None,\n",
    "                   start_date=None,\n",
    "                   end_date=None,\n",
    "                   timestep=200,\n",
    "                   dims=(12,12),\n",
    "                   dpi=150,\n",
    "                   annot=True,\n",
    "                   save_path=None,\n",
    "                   mode='global',\n",
    "                   country=None,\n",
    "                   params=None,\n",
    "                   verbose=True):\n",
    "    ''' wrapper around render_subframe_by_country and render_subframe_by_state'''\n",
    "    \n",
    "    dates = np.sort(data['date'].unique())\n",
    "    if start_date == None:\n",
    "        start_date = dates[0]\n",
    "        \n",
    "    if end_date == None:\n",
    "        end_date = dates[-1]\n",
    "        \n",
    "    dates = dates[np.where((dates >= start_date) & (dates <= end_date))]\n",
    "    n_plots = len(params)\n",
    "    \n",
    "    for date in dates:\n",
    "        for time in range(0,2500,timestep):\n",
    "            # prepare the date+time number\n",
    "            if time == 0:\n",
    "                t = '0000'\n",
    "            elif time < 1000:\n",
    "                t = '0' + str(time)\n",
    "            else:\n",
    "                t = str(time)\n",
    "            \n",
    "            this_time = int(str(date) + t)\n",
    "            fig,axs = plt.subplots(n_plots, figsize=dims)\n",
    "        \n",
    "            ax_ind = 0\n",
    "            for fdict in params:\n",
    "                fdict['time_point'] = this_time\n",
    "                fdict['annot'] = annot\n",
    "                \n",
    "                if n_plots == 1:\n",
    "                    fdict['ax'] = axs\n",
    "                else:\n",
    "                    fdict['ax'] = axs[ax_ind]\n",
    "                    ax_ind += 1\n",
    "            \n",
    "                # render map\n",
    "                if mode == 'global':\n",
    "                    fdict['data'] = data\n",
    "                    render_sub_frame(params=fdict)\n",
    "                elif mode == 'country': \n",
    "                    fdict['data'] = data.loc[data['country'] == country].copy()\n",
    "                    fdict['data'].rename(columns={'country' : 'cnt', 'region' : 'country'}, inplace=True)\n",
    "                    render_sub_frame(params=fdict)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            fig.tight_layout()\n",
    "            fname = save_path + str(this_time) + '.png'\n",
    "            if verbose:\n",
    "                print(fname)\n",
    "            \n",
    "            plt.savefig(fname, dpi=FIG_DPI)\n",
    "            fig.clf()\n",
    "            plt.close()\n",
    "        \n",
    "            # maybe running into RAM problems because creating too many figures\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some defs to use later\n",
    "feature_spread='new_cases'\n",
    "title_spread = 'cumulative cases'\n",
    "\n",
    "feature_deaths='new_deaths'\n",
    "title_deaths='cumulative deaths'\n",
    "\n",
    "# Europe\n",
    "color_max_europe_spread=4  # 10000\n",
    "color_max_europe_deaths=3   # 1000 \n",
    "\n",
    "# South America\n",
    "color_max_samerica_spread=2.7  # 500\n",
    "color_max_samerica_deaths=1   # 1 \n",
    "\n",
    "# world\n",
    "color_max_world_spread=4    # 10000\n",
    "color_max_world_deaths=3 # 1000\n",
    "\n",
    "# USA\n",
    "color_max_usa_spread=3   # 1000\n",
    "color_max_usa_deaths=1   # 10\n",
    "\n",
    "# Africa\n",
    "color_max_africa_spread=2   # 100\n",
    "color_max_africa_deaths=1   # 10\n",
    "\n",
    "# China\n",
    "color_max_china_spread=4    #10,000\n",
    "color_max_china_deaths=3    # 1,000\n",
    "\n",
    "# Asia\n",
    "color_max_asia_spread=4    #10,000\n",
    "color_max_asia_deaths=3    # 1,000\n",
    "\n",
    "# other stuff\n",
    "FIG_DIMS_WORLD=(12,12)\n",
    "FIG_DIMS_AFRICA_SAMERICA=(8,12)\n",
    "FIG_DPI=150\n",
    "TIMESTEP=400 # this is 4 hours, not 400 minutes\n",
    "#TIMESTEP=100  # 1 hour\n",
    "#TIMESTEP=200 # 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define various parameter dictionaries for plotting\n",
    "europe_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_europe_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : europe,\n",
    "    'feature': feature_spread,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "europe_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_europe_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : europe,\n",
    "    'feature': feature_deaths,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "samerica_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_samerica_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : samerica,\n",
    "    'feature': feature_spread,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "samerica_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_samerica_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : samerica,\n",
    "    'feature': feature_deaths,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "world_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_world_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_spread,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "world_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_world_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_deaths,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "usa_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_usa_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : usa,\n",
    "    'feature': feature_spread,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "usa_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_usa_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : usa,\n",
    "    'feature': feature_deaths,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "africa_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_africa_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : africa,\n",
    "    'feature': feature_spread,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "africa_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_africa_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : africa,\n",
    "    'feature': feature_deaths,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "china_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_china_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : china,\n",
    "    'feature': feature_spread,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "china_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_china_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : china,\n",
    "    'feature': feature_deaths,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "asia_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_asia_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : asia,\n",
    "    'feature': feature_spread,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "asia_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_asia_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : asia,\n",
    "    'feature': feature_deaths,\n",
    "    'title_annot' : title_deaths\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_by_region(data=df,\n",
    "               #start_date=20200317,\n",
    "               timestep=TIMESTEP,\n",
    "               dims=FIG_DIMS_WORLD,\n",
    "               annot=True,\n",
    "               params=[asia_spread_dict, asia_death_dict],\n",
    "               mode='global',\n",
    "               #country='China',\n",
    "               #country='United States',\n",
    "               save_path='./asia/',\n",
    "               dpi=FIG_DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
