{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "import geopandas as gpd\n",
    "import geoplot as gplot\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some helper functions first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(line, start_year='2020'):\n",
    "    ''' extract date from dataset'''\n",
    "    \n",
    "    MONTHS = {'January' : '01',\n",
    "              'February' :'02' ,\n",
    "              'March' : '03', \n",
    "              'April' : '04',\n",
    "              'May' : '05',\n",
    "              'June' : '06',\n",
    "              'July' : '07',\n",
    "              'August' : '08',\n",
    "              'September' : '09',\n",
    "              'October' : '10',\n",
    "              'November' : '11',\n",
    "              'December' : '12'}\n",
    "    \n",
    "    date = False\n",
    "    \n",
    "    for m in MONTHS:\n",
    "        pattern = '^\\d+\\s+' + m\n",
    "        if re.match(pattern,line):\n",
    "            tokens = re.split('\\s+',line)\n",
    "            if len(tokens[0]) < 2:\n",
    "                tokens[0] = '0' + tokens[0]    \n",
    "            date = start_year + MONTHS[m] + tokens[0]\n",
    "            \n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freo https://datahub.io/core/world-cities#resource-world-cities\n",
    "world_data = pd.read_csv('world-cities.csv')\n",
    "world_data = world_data.astype({'country' : str, 'subcountry' : str, 'name' : str})\n",
    "countries_l = list(world_data['country'].unique())\n",
    "regions_l = list(world_data['subcountry'].unique())\n",
    "cities_l = list(world_data['name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest data and turn it into list of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest data\n",
    "with open('covid19.txt','r') as f:\n",
    "    # read everything in a single string\n",
    "    text = f.read()\n",
    "\n",
    "# get rid on new lines and build a list\n",
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse data and attempt to extract meaningful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a dict to hold data, will turn it into dataframe later\n",
    "parsed = {}\n",
    "parsed['date'] = []\n",
    "parsed['time'] = []\n",
    "parsed['timestamp'] = []\n",
    "parsed['country'] = []\n",
    "parsed['region'] = []\n",
    "parsed['new_cases'] = []\n",
    "parsed['new_deaths'] = []\n",
    "\n",
    "# parse data\n",
    "# i feel the code below can be greatly improved, it is by no means a very good solution\n",
    "current_date = None\n",
    "for line in lines:   \n",
    "    date = extract_date(line)\n",
    "    if date:\n",
    "        current_date = date\n",
    "        continue\n",
    "\n",
    "    country = 'unknown'\n",
    "    subregion = 'unknown'\n",
    "    city = 'unknown'\n",
    "    new_cases = 0\n",
    "    new_deaths = 0\n",
    "    timestamp = 'unknown'\n",
    "    \n",
    "    # get country\n",
    "    for x in countries_l:\n",
    "        if x in line:\n",
    "            country = x\n",
    "    \n",
    "    # get subregion (state/ provonce etc)\n",
    "    for x in regions_l:\n",
    "        if x in line:\n",
    "            subregion = x\n",
    "    \n",
    "    # get city\n",
    "    for x in cities_l:\n",
    "        if x in line:\n",
    "            city = x\n",
    "    \n",
    "    # try to guess country based on subregion\n",
    "    if country == 'unknown':\n",
    "        if subregion != 'unknown':\n",
    "            country = world_data.loc[world_data['subcountry'] == subregion, 'country'].values[0]\n",
    "    \n",
    "    # try to guess country based on city\n",
    "    if country == 'unknown':\n",
    "        if city != 'unknown':\n",
    "            country = world_data.loc[world_data['name'] == city, 'country'].values[0]\n",
    "    \n",
    "    # give up if country still unknown\n",
    "    if country == 'unknown':\n",
    "        print(line)\n",
    "        continue\n",
    "    \n",
    "    # try to guess subregion based on city\n",
    "    if subregion == 'unknown':\n",
    "        if city != 'unknown':\n",
    "            subregion = world_data.loc[world_data['name'] == city, 'subcountry'].values[0]\n",
    "    \n",
    "    # timestamp\n",
    "    pattern = '^\\d+:\\d+'\n",
    "    z = re.findall(pattern,line)\n",
    "    if z:\n",
    "        timestamp = z[0].split(' ')[0]\n",
    "    else:\n",
    "        timestamp = '00:00'\n",
    "    \n",
    "    line = line.replace(timestamp+': ','')\n",
    "    timestamp = timestamp.replace(':','')\n",
    "    #print(line)\n",
    "    \n",
    "    # new cases\n",
    "    pattern = '\\d+\\s+new\\s+case|\\d+\\s+case'\n",
    "    z = re.findall(pattern,line)\n",
    "    if z:\n",
    "        new_cases = z[0].split(' ')[0]\n",
    "        \n",
    "    pattern = 'First\\s\\d+\\scase'\n",
    "    z = re.findall(pattern,line)\n",
    "    if z:\n",
    "        new_cases = z[0].split(' ')[1]\n",
    "        \n",
    "    pattern = 'First\\s+case'\n",
    "    z = re.findall(pattern,line)\n",
    "    if z:\n",
    "        new_cases = 1\n",
    "    \n",
    "    # deaths\n",
    "    pattern = '\\d+\\s+new\\s+death|\\d+\\s+death'\n",
    "    z = re.findall(pattern,line)\n",
    "    if z:\n",
    "        new_deaths = z[0].split(' ')[0]\n",
    "        \n",
    "    if new_cases == 0 and new_deaths == 0:\n",
    "        continue\n",
    "    \n",
    "    parsed['date'].append(current_date)\n",
    "    parsed['country'].append(country)\n",
    "    parsed['region'].append(subregion)\n",
    "    parsed['timestamp'].append(timestamp)\n",
    "    parsed['time'].append(str(current_date)+str(timestamp))\n",
    "    parsed['new_cases'].append(new_cases)\n",
    "    parsed['new_deaths'].append(new_deaths)\n",
    "    \n",
    "    #print('%s\\t%s\\t%s\\t%s\\t%s\\t%s' %(current_date,timestamp,country,subregion, new_cases, new_deaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create dataframe for further use\n",
    "df = pd.DataFrame(parsed)\n",
    "\n",
    "# convert columns to numeric\n",
    "df = df.astype({'new_cases' : int,\n",
    "                'new_deaths' : int,\n",
    "                'date' : int,\n",
    "                'time' : int,\n",
    "                'timestamp' : int\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load geography maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.loc[world['name'] == 'United States of America', 'name'] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA\n",
    "contiguous_usa = gpd.read_file(gplot.datasets.get_path('contiguous_usa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following 2 functions do the plotting.\n",
    "Both are very similar and I guess I could have writtenjust one and made it very configurable but this keeps the code simpler. Both generate a graphics file and dump it in the current directory. Running them in a loop lets you generate frames which can be animated after with a utility like ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_frame(data=None,\n",
    "                 map_data=None,\n",
    "                 time_point=None,\n",
    "                 feature='new_cases',\n",
    "                 extent=(-180,-90,180,90),\n",
    "                 dims=(16,8),\n",
    "                 dpi=150,\n",
    "                 img_type='png',\n",
    "                 title_annot='new cases',\n",
    "                 cmap='OrRd',\n",
    "                 color_min=0,\n",
    "                 color_max=4,\n",
    "                 verbose=False,\n",
    "                 save=False,\n",
    "                 ax=None):\n",
    "    \n",
    "    '''renders a single frame and dumps a graphics file'''\n",
    "    \n",
    "    # normalize colormap\n",
    "    norm = mpl.colors.Normalize(vmin=color_min, vmax=color_max)\n",
    "    cmap = mpl.cm.ScalarMappable(norm=norm, cmap=cmap).cmap\n",
    "    \n",
    "    # sum numbers by country, take log10\n",
    "    sum_by_country = np.log10(data.loc[ data['time'] <= time_point ].groupby('country')[feature].sum())\n",
    "    #sum_by_country = pd.DataFrame(sum_by_country.rename_axis('name'))\n",
    "    \n",
    "    # merge w/ map data\n",
    "    geodata = map_data.copy()\n",
    "    geodata[feature] = np.zeros(geodata.shape[0])\n",
    "    for country in sum_by_country.index:\n",
    "        geodata.loc[geodata['name'] == country,feature] = sum_by_country.loc[country]\n",
    "    \n",
    "    # plot\n",
    "    if (ax == None):\n",
    "        fig, ax = plt.subplots(figsize=dims)\n",
    "    \n",
    "    #gplot.polyplot(map_data, ax = ax)\n",
    "    gplot.choropleth(geodata,\n",
    "                     hue=feature,\n",
    "                     cmap=cmap,\n",
    "                     ax=ax,\n",
    "                     norm=norm,\n",
    "                     extent=extent,\n",
    "                     legend = True)\n",
    "    \n",
    "    # derive date and time for plot title\n",
    "    str_date = str(time_point)[0:4] + '-' +str(time_point)[4:6]+ '-' +str(time_point)[6:8]\n",
    "    str_time = str(time_point)[8:]\n",
    "    \n",
    "    ax.set_title('COVID19 '+ title_annot +' over time ' + str_date + ' ' + str_time)\n",
    "            \n",
    "    if save:\n",
    "        fname = str(time_point) + '.'+img_type\n",
    "        \n",
    "        if verbose:\n",
    "            print(fname)\n",
    "        \n",
    "        plt.savefig(fname, dpi=dpi)\n",
    "        fig.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_frame_usa(data=None,\n",
    "                     map_data=None,\n",
    "                     time_point=None,\n",
    "                     feature='new_cases',\n",
    "                     extent=(-130,25,-65,55),\n",
    "                     dims=(16,8),\n",
    "                     dpi=150,\n",
    "                     img_type='png',\n",
    "                     title_annot='new cases',\n",
    "                     cmap='OrRd',\n",
    "                     color_min=0,\n",
    "                     color_max=3,\n",
    "                     verbose=False,\n",
    "                     save=False,\n",
    "                     ax=None):\n",
    "    \n",
    "    '''renders a single frame and dumps a graphics file'''\n",
    "    \n",
    "    # normalize colormap\n",
    "    norm = mpl.colors.Normalize(vmin=color_min, vmax=color_max)\n",
    "    cmap = mpl.cm.ScalarMappable(norm=norm, cmap=cmap).cmap\n",
    "    \n",
    "    # sum numbers by country, take log10\n",
    "    usa = data.loc[data['country'] == 'United States']\n",
    "    sum_by_state = np.log10(usa.loc[ usa['time'] <= time_point ].groupby('region')[feature].sum())\n",
    "    \n",
    "    # merge w/ map data\n",
    "    geodata = map_data.copy()\n",
    "    geodata[feature] = np.zeros(geodata.shape[0])\n",
    "    for state in sum_by_state.index:\n",
    "        geodata.loc[geodata['state'] == state,feature] = sum_by_state.loc[state]\n",
    "    \n",
    "    # plot\n",
    "    if (ax == None):\n",
    "        fig, ax = plt.subplots( nrows=1, ncols=1, figsize=dims)\n",
    "    \n",
    "    gplot.choropleth(geodata,\n",
    "                     hue=feature,\n",
    "                     cmap=cmap,\n",
    "                     ax=ax,\n",
    "                     norm=norm,\n",
    "                     extent=extent,\n",
    "                     legend = True)\n",
    "    \n",
    "    # derive date and time for plot title\n",
    "    str_date = str(time_point)[0:4] + '-' +str(time_point)[4:6]+ '-' +str(time_point)[6:8]\n",
    "    str_time = str(time_point)[8:]\n",
    "    \n",
    "    ax.set_title('COVID19 USA '+ title_annot +' over time ' + str_date + ' ' + str_time)\n",
    "        \n",
    "    if save:\n",
    "        fname = str(time_point) + '.'+img_type\n",
    "        \n",
    "        if verbose:\n",
    "            print(fname)\n",
    "        \n",
    "        plt.savefig(fname, dpi=dpi)\n",
    "        fig.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_sub_frame_per_country(params=None): \n",
    "\n",
    "    # normalize colormap\n",
    "    norm = mpl.colors.Normalize(vmin=params['color_min'], vmax=params['color_max'])\n",
    "    cmap = mpl.cm.ScalarMappable(norm=norm, cmap=params['cmap']).cmap\n",
    "    \n",
    "    # sum numbers by country, take log10\n",
    "    sum_ = np.log10(params['data'].loc[ params['data']['time'] <= params['time_point'] ].groupby('country')[params['feature']].sum())\n",
    "    \n",
    "    # merge w/ map data\n",
    "    geodata = params['map_data'].copy()\n",
    "    geodata[params['feature']] = np.zeros(geodata.shape[0])\n",
    "    \n",
    "    for country in sum_.index:\n",
    "        geodata.loc[geodata['name'] == country,params['feature']] = sum_.loc[country]\n",
    "    \n",
    "    gplot.choropleth(geodata,\n",
    "                     hue=params['feature'],\n",
    "                     cmap=cmap,\n",
    "                     ax=params['ax'],\n",
    "                     norm=norm,\n",
    "                     extent=params['extent'],\n",
    "                     legend = True)\n",
    "    \n",
    "    # derive date and time for plot title\n",
    "    str_date = str(params['time_point'])[0:4] + '-' +str(params['time_point'])[4:6]+ '-' +str(params['time_point'])[6:8]\n",
    "    str_time = str(params['time_point'])[8:] \n",
    "    params['ax'].set_title('COVID19 '+ params['title_annot'] +' over time ' + str_date + ' ' + str_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_sub_frame_per_state(params=None): \n",
    "\n",
    "    # normalize colormap\n",
    "    norm = mpl.colors.Normalize(vmin=params['color_min'], vmax=params['color_max'])\n",
    "    cmap = mpl.cm.ScalarMappable(norm=norm, cmap=params['cmap']).cmap\n",
    "    \n",
    "    # sum numbers by country, take log10\n",
    "    usa = params['data'].loc[params['data']['country'] == 'United States']\n",
    "    sum_ = np.log10(usa.loc[ usa['time'] <= params['time_point'] ].groupby('region')[params['feature']].sum())\n",
    "    \n",
    "    # merge w/ map data\n",
    "    geodata = params['map_data'].copy()\n",
    "    geodata[params['feature']] = np.zeros(geodata.shape[0])\n",
    "    \n",
    "    for state in sum_.index:\n",
    "        geodata.loc[geodata['state'] == state,params['feature']] = sum_.loc[state]\n",
    "    \n",
    "    gplot.choropleth(geodata,\n",
    "                     hue=params['feature'],\n",
    "                     cmap=cmap,\n",
    "                     ax=params['ax'],\n",
    "                     norm=norm,\n",
    "                     extent=params['extent'],\n",
    "                     legend = True)\n",
    "    \n",
    "    # derive date and time for plot title\n",
    "    str_date = str(params['time_point'])[0:4] + '-' +str(params['time_point'])[4:6]+ '-' +str(params['time_point'])[6:8]\n",
    "    str_time = str(params['time_point'])[8:] \n",
    "    params['ax'].set_title('COVID19 USA'+ params['title_annot'] +' over time ' + str_date + ' ' + str_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_region(data=None,\n",
    "                    start_date=None,\n",
    "                    end_date=None,\n",
    "                    timestep=200,\n",
    "                    dims=(12,12),\n",
    "                    dpi=150,\n",
    "                    mode='country',\n",
    "                    params=None):\n",
    "    ''' wrapper around render_subframe_by_country and render_subframe_by_state'''\n",
    "    \n",
    "    dates = np.sort(data['date'].unique())\n",
    "    if start_date == None:\n",
    "        start_date = dates[0]\n",
    "        \n",
    "    if end_date == None:\n",
    "        end_date = dates[-1]\n",
    "        \n",
    "    dates = dates[np.where((dates >= start_date) & (dates <= end_date))]\n",
    "    n_plots = len(params)\n",
    "    \n",
    "    for date in dates:\n",
    "        for time in range(0,2500,timestep):\n",
    "            # prepare the date+time number\n",
    "            if time == 0:\n",
    "                t = '0000'\n",
    "            elif time < 1000:\n",
    "                t = '0' + str(time)\n",
    "            else:\n",
    "                t = str(time)\n",
    "            \n",
    "            this_time = int(str(date) + t)\n",
    "            fig,axs = plt.subplots(n_plots, figsize=dims)\n",
    "        \n",
    "            ax_ind = 0\n",
    "            for fdict in params:\n",
    "                fdict['data'] = data\n",
    "                fdict['time_point'] = this_time\n",
    "                \n",
    "                if n_plots == 1:\n",
    "                    fdict['ax'] = axs\n",
    "                else:\n",
    "                    fdict['ax'] = axs[ax_ind]\n",
    "                    ax_ind += 1\n",
    "            \n",
    "                # render map\n",
    "                if mode == 'country':\n",
    "                    render_sub_frame_per_country(params=fdict)\n",
    "                else:\n",
    "                    render_sub_frame_per_state(params=fdict)\n",
    "                \n",
    "            plt.savefig(str(this_time) + '.png', dpi=FIG_DPI)\n",
    "            fig.clf()\n",
    "            plt.close()\n",
    "        \n",
    "            # maybe running into RAM problems because creating too many figures\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some defs to use later\n",
    "feature_spread='new_cases'\n",
    "title_spread = 'cumulative cases'\n",
    "\n",
    "feature_deaths='new_deaths'\n",
    "title_deaths='cumulative deaths'\n",
    "\n",
    "# Europe\n",
    "extent_europe=(-20,30,60,80)\n",
    "color_max_europe_spread=3  # 1000\n",
    "color_max_europe_deaths=2.7   # 500 \n",
    "\n",
    "# world\n",
    "extent_world=(-180,-90,180,90)\n",
    "color_max_world_spread=4    # 10000\n",
    "color_max_world_deaths=3 # 1000\n",
    "\n",
    "# USA\n",
    "color_max_usa_spread=3   # 1000\n",
    "color_max_usa_deaths=1   # 10\n",
    "extent_usa=(-130,25,-65,55)\n",
    "\n",
    "# Africa\n",
    "color_max_africa_spread=2   # 100\n",
    "color_max_africa_deaths=1   # 10\n",
    "extent_africa=(-25,-40,60,50)\n",
    "\n",
    "# other stuff\n",
    "FIG_DIMS_WORLD_USA=(12,12)\n",
    "FIG_DIMS_AFRICA=(8,12)\n",
    "FIG_DPI=150\n",
    "TIMESTEP= 200 # this is 2 hours, not 200 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define various parameter dictionaries for plotting\n",
    "europe_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_europe_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_spread,\n",
    "    'extent' : extent_europe,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "europe_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_europe_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_deaths,\n",
    "    'extent' : extent_europe,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "world_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_world_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_spread,\n",
    "    'extent' : extent_world,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "world_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_world_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_deaths,\n",
    "    'extent' : extent_world,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "usa_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_usa_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : contiguous_usa,\n",
    "    'feature': feature_spread,\n",
    "    'extent' : extent_usa,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "usa_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_usa_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : contiguous_usa,\n",
    "    'feature': feature_deaths,\n",
    "    'extent' : extent_usa,\n",
    "    'title_annot' : title_deaths\n",
    "}\n",
    "\n",
    "africa_spread_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_africa_spread,\n",
    "    'cmap' : 'Greens',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_spread,\n",
    "    'extent' : extent_africa,\n",
    "    'title_annot' : title_spread\n",
    "}\n",
    "\n",
    "africa_death_dict = {\n",
    "    'color_min' : 0,\n",
    "    'color_max' : color_max_africa_deaths,\n",
    "    'cmap' : 'Reds',\n",
    "    'map_data' : world,\n",
    "    'feature': feature_deaths,\n",
    "    'extent' : extent_africa,\n",
    "    'title_annot' : title_deaths\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_by_region(data=df,\n",
    "               timestep=TIMESTEP,\n",
    "               dims=FIG_DIMS_WORLD_USA,\n",
    "               params=[usa_spread_dict, usa_death_dict],\n",
    "               mode='usa',\n",
    "               dpi=FIG_DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
